name: Daily Proxy Update

on:
  schedule:
    # 每天 UTC 0:00 和 12:00 运行（北京 08:00/20:00）
    - cron: '0 0 * * *'
    - cron: '0 12 * * *'
  # 手动触发测试
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install pyyaml

    - name: Fetch subscription links
      id: fetch
      run: |
        # 安装 Node.js
        curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
        sudo apt-get install -y nodejs
        
        # 安装 Puppeteer + 反检测插件
        npm install puppeteer puppeteer-extra puppeteer-extra-plugin-stealth
        
        # Puppeteer 脚本：访问主页面设置 cookie，然后用请求获取 API
        node -e "
        const puppeteer = require('puppeteer-extra');
        const StealthPlugin = require('puppeteer-extra-plugin-stealth');
        puppeteer.use(StealthPlugin());
        const fs = require('fs');
        const https = require('https');
        (async () => {
          const browser = await puppeteer.launch({ 
            headless: true, 
            args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage', '--disable-blink-features=AutomationControlled']
          });
          const page = await browser.newPage();
          await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36');
          await page.evaluateOnNewDocument(() => {
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            window.chrome = { runtime: {} };
          });
          
          console.log('Accessing initial page to set cookies...');
          await page.goto('https://www.bsbb.cc/sub/index.php', { 
            waitUntil: 'domcontentloaded',
            timeout: 30000 
          });
          
          console.log('Waiting 12 seconds for redirect...');
          await new Promise(resolve => setTimeout(resolve, 12000));
          
          // 模拟滚动防检测
          await page.evaluate(() => window.scrollTo(0, 100));
          
          const finalUrl = page.url();
          console.log('Final URL after wait:', finalUrl);
          
          if (!finalUrl.includes('/api/sub.php?t=') || finalUrl === 'https://www.bsbb.cc/sub/index.php') {
            console.log('No valid redirect detected. Workflow failed.');
            await browser.close();
            process.exit(1);
          }
          
          // 获取 cookie
          const cookies = await page.cookies();
          const cookieString = cookies.map(c => c.name + '=' + c.value).join('; ');
          console.log('Cookies set (' + cookies.length + ' cookies), fetching with cookies...');
          
          await browser.close();
          
          // 用 https 请求 API，带 cookie
          return new Promise((resolve, reject) => {
            const req = https.request(finalUrl, {
              method: 'GET',
              headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Cookie': cookieString,
                'Referer': 'https://www.bsbb.cc/sub/index.php'
              }
            }, (res) => {
              let data = '';
              res.on('data', chunk => data += chunk);
              res.on('end', () => {
                fs.writeFileSync('raw-sub.txt', data.trim());
                const length = data.length;
                if (length < 1000 || data.includes('访问受限') || data.includes('Verify')) {
                  console.log('Failed: Restriction or short content. Preview:', data.substring(0, 200));
                  reject(new Error('Content invalid'));
                } else {
                  console.log('Success! Fetched length:', length);
                  console.log('Preview:', data.substring(0, 50));
                  resolve();
                }
              });
            });
            req.on('error', reject);
            req.end();
          });
        })().catch(err => { 
          console.error('Error:', err.message);
          process.exit(1); 
        });
        "

    - name: Decode and filter to input_nodes.txt (vless/Trojan only)
      run: |
        python -c "
        import base64
        import yaml
        from urllib.parse import quote
        
        with open('raw-sub.txt', 'r') as f:
            content = f.read().strip()
        
        # 假设 base64 编码，解码
        try:
            decoded = base64.b64decode(content).decode('utf-8')
        except:
            decoded = content  # 如果非 base64，直接用
        
        data = yaml.safe_load(decoded)
        proxies = data.get('proxies', []) if data else []
        
        with open('input_nodes.txt', 'w', encoding='utf-8') as f:
            for p in proxies:
                if p['type'] in ['vless', 'trojan']:
                    # 生成 URI (简化，基于 params)
                    if p['type'] == 'vless':
                        query_parts = []
                        if 'network' in p: query_parts.append(f'type={p[\"network\"]}')
                        if p.get('tls', False): query_parts.append('security=tls')
                        if 'flow' in p: query_parts.append(f'flow={p[\"flow\"]}')
                        if 'sni' in p: query_parts.append(f'sni={p[\"sni\"]}')
                        if 'path' in p: query_parts.append(f'path={quote(p[\"path\"])}')
                        query = '&'.join(query_parts)
                        uri = f'vless://{quote(p[\"uuid\"])}@{p[\"server\"]}:{p[\"port\"]}?{query}' if query else f'vless://{quote(p[\"uuid\"])}@{p[\"server\"]}:{p[\"port\"]}'
                    elif p['type'] == 'trojan':
                        query_parts = []
                        if 'sni' in p: query_parts.append(f'sni={p[\"sni\"]}')
                        if 'network' in p: query_parts.append(f'type={p[\"network\"]}')
                        if 'path' in p: query_parts.append(f'path={quote(p[\"path\"])}')
                        query = '&'.join(query_parts)
                        uri = f'trojan://{quote(p[\"password\"])}@{p[\"server\"]}:{p[\"port\"]}?{query}' if query else f'trojan://{quote(p[\"password\"])}@{p[\"server\"]}:{p[\"port\"]}'
                    
                    name = p.get('name', f'{p[\"type\"]} Unnamed')
                    f.write(f'{uri}#{name}\n')
        
        import os
        with open('input_nodes.txt', 'r', encoding='utf-8') as f:
            num_lines = sum(1 for line in f if line.strip())
        print(f'Generated {num_lines} vless/Trojan URIs to input_nodes.txt')
        "

    - name: Convert to Stash format and cover output
      run: |
        # 运行脚本：输入 input_nodes.txt，输出覆盖 nodes.yaml
        python node_converter.py input_nodes.txt nodes.yaml
        
        # 检查输出
        if [ ! -s nodes.yaml ]; then
          echo "Conversion failed. Exiting."
          exit 1
        fi

    - name: Backup original (optional)
      run: |
        if [ -f nodes.yaml ]; then
          cp nodes.yaml nodes.yaml.bak.$(date +'%Y%m%d-%H%M%S')
        fi

    - name: Commit and push changes
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        
        # 检查是否有变化（nodes.yaml 和 input_nodes.txt）
        if git diff --quiet -- nodes.yaml input_nodes.txt; then
          echo "No changes to commit."
        else
          git add nodes.yaml input_nodes.txt
          git commit -m "Auto-update proxies from BSBB on $(date +'%Y-%m-%d %H:%M')"
          git push
          echo "Updated and pushed successfully!"
        fi
